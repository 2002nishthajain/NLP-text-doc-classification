{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "News                     324\n",
       "Research Paper            61\n",
       "Code/Perl                 10\n",
       "Code/Markdown             10\n",
       "Code/Erlang               10\n",
       "Code/Visual Basic         10\n",
       "Code/Groovy               10\n",
       "Code/Objective-C          10\n",
       "Code/JavaScript           10\n",
       "Code/Batchfile            10\n",
       "Code/PHP                  10\n",
       "Code/C#                   10\n",
       "Code/Julia                10\n",
       "Code/Python               10\n",
       "Code/Rust                 10\n",
       "Code/TeX                  10\n",
       "Code/C++                  10\n",
       "Code/Java                 10\n",
       "Code/Pascal               10\n",
       "Code/Haskell              10\n",
       "Code/Shell                10\n",
       "Code/C                    10\n",
       "Code/Jupyter Notebook     10\n",
       "Code/Ruby                 10\n",
       "Code/Swift                10\n",
       "Code/HTML                 10\n",
       "Code/SQL                  10\n",
       "Code/Go                   10\n",
       "Code/Dart                 10\n",
       "Code/Scala                10\n",
       "Code/TypeScript           10\n",
       "Code/PowerShell           10\n",
       "Code/Lua                  10\n",
       "Code/CoffeeScript         10\n",
       "Code/Kotlin               10\n",
       "Code/CSS                  10\n",
       "Name: main_category, dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Step 1: Read the CSV file\n",
    "data = pd.read_csv('../Dataset/combined_final_dataset.csv')\n",
    "data.describe\n",
    "#count for each class\n",
    "data['main_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: said, Frequency: 33\n",
      "Word: new, Frequency: 31\n",
      "Word: year, Frequency: 21\n",
      "Word: one, Frequency: 20\n",
      "Word: two, Frequency: 18\n",
      "Word: trump, Frequency: 17\n",
      "Word: day, Frequency: 16\n",
      "Word: president, Frequency: 16\n",
      "Word: people, Frequency: 15\n",
      "Word: say, Frequency: 15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#create a separate list of descriptions for each class in main_category column\n",
    "preprocessed_text_news = data[data['main_category'] == 'News']['description'].tolist()\n",
    "preprocessed_text_research = data[data['main_category'] == 'Research Paper']['description'].tolist()\n",
    "\n",
    "\n",
    "# Step 3: Word Frequency Analysis for news category\n",
    "# Create a vocabulary and count word occurrences\n",
    "vectorizer = CountVectorizer()\n",
    "word_freq_matrix = vectorizer.fit_transform(preprocessed_text_news)\n",
    "\n",
    "# Get the word frequency counts\n",
    "word_freq_counts = word_freq_matrix.sum(axis=0)\n",
    "\n",
    "# Create a list of words and their corresponding frequencies\n",
    "word_freq_list = [(word, word_freq_counts[0, id]) for word, id in vectorizer.vocabulary_.items()]\n",
    "\n",
    "# Sort the word frequency list in descending order of frequencies\n",
    "sorted_word_freq_list = sorted(word_freq_list, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display the top 10 words with their frequencies\n",
    "top_words = sorted_word_freq_list[:10]\n",
    "for word, freq in top_words:\n",
    "    print(f\"Word: {word}, Frequency: {freq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: quantum, Frequency: 30\n",
      "Word: result, Frequency: 28\n",
      "Word: method, Frequency: 27\n",
      "Word: model, Frequency: 23\n",
      "Word: field, Frequency: 21\n",
      "Word: system, Frequency: 20\n",
      "Word: theory, Frequency: 19\n",
      "Word: also, Frequency: 18\n",
      "Word: present, Frequency: 18\n",
      "Word: show, Frequency: 18\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "word_freq_matrix = vectorizer.fit_transform(preprocessed_text_research)\n",
    "\n",
    "# Get the word frequency counts\n",
    "word_freq_counts = word_freq_matrix.sum(axis=0)\n",
    "\n",
    "# Create a list of words and their corresponding frequencies\n",
    "word_freq_list = [(word, word_freq_counts[0, id]) for word, id in vectorizer.vocabulary_.items()]\n",
    "\n",
    "# Sort the word frequency list in descending order of frequencies\n",
    "sorted_word_freq_list = sorted(word_freq_list, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display the top 10 words with their frequencies\n",
    "top_words = sorted_word_freq_list[:10]\n",
    "for word, freq in top_words:\n",
    "    print(f\"Word: {word}, Frequency: {freq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
